---
title: "chapter4.Rmd"
author: "Ahi"
date: "25 marraskuuta 2017"
output: html_document
---

```{r}
library(tidyr)
library(ggplot2)
library(corrplot)
library(GGally)
```

# 2. Loading the Boston data and exploring the data

```{r}
library(MASS)
data("Boston")
str(Boston)
summary(Boston)
```

According to the structure of the data, Boston dataset, which is already loaded in R, has 506 observattions (rows) and 14 variables (columns). The data are mainly gathered to understand the effect of housing values in suburbs of Boston on different vairbles such as crime rate.  

# 3. Graphical overview of the data and summary of variables 

```{r}
pairs(Boston)
```

The plot above shows the correlations of all the variables in the dataset. But let's look at a more advanced plot to see the distribution of the data as well as correlation of the variables.

```{r}
p <- ggpairs(Boston, mapping = aes(alpha = 0.3), lower = list(combo = wrap("facethist", bins = 20)))
p
```

The above plot demonstrates the distribution of the data as well as the correlations of the variables. As an example, data in the variable "rm", average number of room per dwelling, have normal distribution, and there is a positive, and rather strong, correlation between "zn" (proportion of residential land zoned for lots over 25,000 sq.ft.), and "dis" (weighted mean of distances to five Boston employment centres).

But we can look at the corraltions with more r funcations. Let's explore cor_matrix function, which provides handy, easy-to-interpret-correlation matrix. 

```{r}
cor_matrix<-cor(Boston) %>% round(digit=2)

cor_matrix %>% round(cor_matrix)

corrplot(cor_matrix, method="circle", type = "upper", cl.pos = "b", tl.pos = "d", tl.cex = 0.6)
```

Let's explore some examples. We can see that there is a strong and positive relationship between "rad" (index of accessibility to radial highways) and "tax" (full-value property-tax rate per \$10,000). In addition, there is a negtive and strong relationship between "lstat" (lower status of the population (percent)) and "medv" (median value of owner-occupied homes in \$1000s). 

# 4. Standardizing the dataset

```{r}
boston_scaled <- scale(Boston)
summary(boston_scaled)
class(boston_scaled)
boston_scaled <- as.data.frame(boston_scaled)
```

Creating a categorical variable of the crime rate in the Boston dataset. First, let's create a quantile vector of crime rate.

```{r}
bins <- quantile(boston_scaled$crim)
bins
```

Now, let's create a categorical variable, and call it, 'crime':
```{r}
crime <- cut(boston_scaled$crim, breaks = bins, include.lowest = TRUE, c(label = "low", "med_low", "med_high", "high"))
table(crime)
```

Now, let's remove the original "crim"" from the dataset
```{r}
boston_scaled <- dplyr::select(boston_scaled, -crim)
```

And add the new categorical value to scaled data
```{r}
boston_scaled <- data.frame(boston_scaled, crime)
```

Dividing the dataset to train and test sets, so that 80% of the data belongs to the train set. 
```{r}
n <- nrow(boston_scaled)
ind <- sample(n,  size = n * 0.8)
train <- boston_scaled[ind,]
test <- boston_scaled[-ind,]
correct_classes <- test$crime
test <- dplyr::select(test, -crime)
```

# Fitting the linear discriminant analysis (LDA) on the train dataset 

Use the crime as a target variable and all the other variables as predictors.
```{r}
lda.fit <- lda(crime ~ ., data = train)
lda.fit
```

Drawing the LDA (bi)plot. But first let's create a numeric vector of the train sets crime classes.
```{r}
classes <- as.numeric(train$crime)
```

Now we're ready to draw the LDA plot.
```{r}
lda.arrows <- function(x, myscale = 1, arrow_heads = 0.1, color = "red", tex = 0.75, choices = c(1,2)){
  heads <- coef(x)
  arrows(x0 = 0, y0 = 0, 
         x1 = myscale * heads[,choices[1]], 
         y1 = myscale * heads[,choices[2]], col=color, length = arrow_heads)
  text(myscale * heads[,choices], labels = row.names(heads), 
       cex = tex, col=color, pos=3)
}

plot(lda.fit, dimen = 2, col = classes, pch = classes)
lda.arrows(lda.fit, myscale = 3)
```

