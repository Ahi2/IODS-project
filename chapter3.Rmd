---
title: "chapter3.Rmd"
author: "Ahi"
date: "19 marraskuuta 2017"
output: html_document
---

library(tidyr)
library(dplyr)
library(ggplot2)

# 2. Reading the joined dataset

```{r}
alc <- read.table("C:/Data/IODS-project/alc.csv", sep=",", header=TRUE)
```

This is a dataset which contains information on students achievment in two classes, math and Portuguese language. The aim is to see, e.g., how alocohol consumtpion and gender affect students' performance. The name of the variables used can be seen here:

```{r}
colnames(alc)
```

# 3. The hypotheses regarding four variables and alc consumption

Now we want to study the effect of students' gender, age, health, and final grade (G3) on students' alcohol consumption...we use high_consumption as the dependent variable...

# 4. exploring the distribution of the variables 
Let's look at the disribution of the variables selected:

```{r}
g1 <- ggplot(data = alc, aes(x = high_use)) + facet_wrap("sex")

g1 + geom_bar()

g2 <- ggplot(alc, aes(x = high_use, y = G3, col = sex))

g2 + geom_boxplot() + ylab("grade")

g3 <- ggplot(alc, aes(x = high_use, y = health, col = sex)) + ggtitle("Student health by alcohol consumption and sex")

g3 + geom_boxplot() + ylab("health")

g4 <- ggplot(alc, aes(x = high_use, y = age)) + ggtitle("Student age by alcohol consumption")

g4 + geom_boxplot() + ylab("age")
```

# 5. Logistic regression

looking at the logistic model, where alcohol consumption is the depedent variables, which is binory (0 and 1), and gender, health, age, and grade are independent variables. 
```{r}
m <- glm(high_use ~ sex + G3 + health + age, data = alc, family = "binomial")
```

printing out the model:
```{r}
m
```

coefficients and the summary of the model

```{r}
coef(m)
summary(m)
```
Computing odds ratios (OR)

```{r}
OR <- coef(m) %>% exp
```

computing confidence intervals (CI)

```{r}
CI <- confint(m) %>% exp
```
Printing out the odds ratios with their confidence intervals
```{r}
cbind(OR, CI)
```
As can be seen from the results, the gender has the widest confidence interval. 

# 6. Exploring the predictive power of the model

Using the variables which were statistically signifacnt in a model called m2 
```{r}
m2 <- glm(high_use ~ sex + G3 + age, data = alc, family = "binomial")
```

looking at the predictive power of m2

```{r}
probabilities <- predict(m, type = "response")
```

adding the  predicted probabilities to 'alc'
```{r}
alc <- mutate(alc, probability = probabilities)
```

using the probabilities to make a prediction of high_use
```{r}
alc <- mutate(alc, prediction = probability > 0.5)
```

Looking at the last ten original classes, predicted probabilities, and class predictions
```{r}
select(alc, sex, G3, age, high_use, probability, prediction) %>% tail(10)
```

tabulating the target variable versus the predictions
```{r}
table(high_use = alc$high_use, prediction = alc$prediction)
```

displaying the actual values and the predictions
```{r}
g <- ggplot(alc, aes(x = probability, y = high_use, col = prediction))

g + geom_point()
```

Computing the total proportion of inaccurately classified individuals 
```{r}
loss_func <- function(class, prob) {
  n_wrong <- abs(class - prob) > 0.5
  mean(n_wrong)
}

loss_func(class = alc$high_use, prob = alc$probability)
```
 
# 7 and 8. Performing cross-validation to compare different models

library(boot)
```{r}
cv <- cv.glm(data = alc, cost = loss_func, glmfit = m, K = 10)
cv$delta[1]
```
After performing this 10-fold crosss-validation test, we can see that the prediction error is larger than the model in the DataCamp (~ 0.29 > 0.26). Therefore, it seems that this model does not perform better. Let's now use m2 model, in which one of the variables (health) that was insignificant is removed.

```{r}
cv <- cv.glm(data = alc, cost = loss_func, glmfit = m2, K = 10)
cv$delta[1]
```
Though the prediction error of this model is slightly better than the other one (m1), it still is larger than the one in DataCamp. So, let's remove the variable "age", and keep only the "sex" and "G3", which are more significant statistically. Let's call the model, m3:

```{r}
m3 <- glm(high_use ~ sex + G3, data = alc, family = "binomial")
```

Now, let's look at the prediction error of m3:

```{r}
cv <- cv.glm(data = alc, cost = loss_func, glmfit = m3, K = 10)
cv$delta[1]
```
Still the prediction error is larger. So, let's introduce new variables to the model: absences and sex, and remove G3.   

```{r}
m4 <- glm(high_use ~ sex + absences, data = alc, family = "binomial")

cv <- cv.glm(data = alc, cost = loss_func, glmfit = m4, K = 10)
cv$delta[1]
```

As can be seen, now the predictive error of the model is smaller than the previous models. It is however the same as the one in the DataCamp exercise.


